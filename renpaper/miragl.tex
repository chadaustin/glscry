% ---------------------------------------------------------------------------
% Author guideline and sample document for EG publication using LaTeX2e input
% D.Fellner, v1.11, Feb 28, 2005

\documentclass{egpubl}
\usepackage{gh05}

% --- for  Annual CONFERENCE
% \ConferenceSubmission % uncomment for Conference submission
% \ConferencePaper      % uncomment for (final) Conference Paper
% \STAR                 % uncomment for STAR contribution
% \Tutorial             % uncomment for Tutorial contribution
% \ShortPresentation    % uncomment for (final) Short Conference Presentation
%
% --- for  CGF Journal
% \JournalSubmission    % uncomment for submission to Computer Graphics Forum
% \JournalPaper         % uncomment for final version of Journal Paper
%
% --- for  EG Workshop Proceedings
 \WsSubmission    % uncomment for submission to EG Workshop
% \WsPaper         % uncomment for final version of EG Workshop contribution
%
 \electronicVersion % comment if producing the printed version


% !! *please* don't change anything above
% !! unless you REALLY know what you are doing
% ------------------------------------------------------------------------

% for including postscript figures
% mind: package option 'draft' will replace PS figure by a filename within a frame
\ifpdf \usepackage[pdftex]{graphicx} \pdfcompresslevel=9
\else \usepackage[dvips]{graphicx} \fi

\PrintedOrElectronic

% prepare for electronic version of your document
\usepackage{t1enc,dfadobe}

\usepackage{egweblnk}
\usepackage{cite}

% For backwards compatibility to old LaTeX type font selection.
% Uncomment if your document adheres to LaTeX2e recommendations.
\let\rm=\rmfamily    \let\sf=\sffamily    \let\tt=\ttfamily
\let\it=\itshape     \let\sl=\slshape     \let\sc=\scshape
\let\bf=\bfseries

% end of prologue

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
\providecommand{\LyX}{L\kern-.1667em\lower.25em\hbox{Y}\kern-.125emX\@}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.


\title[Renaissance : A Functional Shading Language]{Renaissance : A Functional Shading Language}


\author[C. Austin \& D. Reiners]{Chad Austin and Dirk Reiners\\
Human-Computer Interaction Program\\
Iowa State University\\
\{aegisk,dreiners\}@iastate.edu }

\begin{document}

\maketitle
\begin{abstract}
Abstract here. I usually so this at the end, because I don't know
what the topic's going to be until then .;)

\CCScat{I.3.7}{Computer Graphics}{Shading}


\end{abstract}

\section{Introduction}

The most important innovation in computer graphics hardware over the last 
decade has been the introduction of programmability. Textures were a first
step  towards fine-grain control over the rendered pixels, and together with
multi-pass  rendering and later multi-textured pipeline configurability they
allowed some  basic implementations of user-specific calculations in the
graphics hardware. But mapping general algorithms to the very limited
and non-intuitive  operations that were possible in this way remained
something of a black art, as  witnessed by the many papers that were
published on mapping specific algorithms to graphics hardware 
(\cite{kautz99interactive,heidrich01Shading,kautztowards} et al.). 

Offline rendering for animation had been using much more general languages
for a long time \cite{HanrahanRenderman}, and some attempts were made to map 
them to a slightly extended version of the fixed-function OpenGL pipeline 
\cite{peercy00interactive}. But the real breakthrough came with actual
programs that were executed on the graphics hardware. 

The first steps were assembly languages for 
register machines.  This was a great step forward for generalizing graphics hardware, but it 
had its limitations.  The shading algorithms were not easy to follow and it
was hard to create building blocks of functionality on which the rest of the 
shader was built.  The next natural step was a high-level language built on top of 
the assembly.  These languages often look like C, both in syntax and semantics.  
There are also metaprogramming languages built on top of a host language.  
These allow tight integration between the host language and the graphics 
processor as well as straightforward shader specialization.

With the advent of Cg's interface features and looking at shaders (i.e. a 
program or programs that runs on the GPU) as elements
of an algebra \cite{mccool-shader}, we're just now starting to see support 
for composable shaders.

In this work we introduce a language that is built on modern functional
languages and their pure semantics instead of the procedural roots used
before. The functional approach significantly simplifies compilation and
analysis of the program, opening up new avenues for more general
optimizations and compositions.

\section{Related Work}

\subsection{Multi-Pass Texture Blending }

Real-time programmable shading appeared in an early form as multi-pass 
rendering along with multi-texturing blend modes.  The Quake 3 engine for 
example provided a simple shader scripting language to control the number of 
passes, texture stages, and rendering state.  This isn't a complete solution for 
general shading, but it goes a long way towards allowing the implementation of 
several surface descriptions.  Peercy, Olano et al. discovered that an OpenGL 
implementation, with some key extensions, can be treated as a general-purpose 
SIMD computer in their OpenGL Shader work \cite{peercy00interactive}.  OpenGL Shader can support 
arbitrary shading computation, using multiple rendering passes.

However, the trend for processors in general; and graphics processors specifically has gone towards higher clock speeds on the 
processor, but slower and higher latency memory access.  This precludes large-
scale multipass implementations of shading from being viable, due to the very 
high memory bandwidth requirements.


\subsection{RTSL}

Stanford's real time programmable shading system, RTSL \cite{rtsl}, introduced the 
concept of computational frequency.  They defined four frequencies: constant, 
primitive group, vertex, and fragment.  Constant computation is done at compile 
time and not during the processing of geometry.  Primitive group computation is 
done per batch of geometry.  Vertex and fragment computations are done per 
vertex, and per fragment.  RTSL has a retargetable backend that can 
map vertex computation to either the CPU or to basic programmable vertex 
hardware.  Fragment computation is mapped to multipass OpenGL, as in 
OpenGL shader above, or early fragment processing hardware -- NVIDIA's 
register combiners.  Their shading language did not differentiate between 
vertex and fragment hardware in the programs themselves.  The compiler was 
responsible for splitting the work up among the various computational stages.  In 
many cases, frequency analysis was implicit, but they allowed explicit
specification of where computation is to be done; for example, to easily compare two lighting 
algorithms, one per vertex and the other per fragment.


\subsection{Assembly Languages (ARBfp, ARBvp, DirectX shader models)}

The next generation of shading languages allowed full programmability at the 
vertex and pixel levels via assembly languages for a vector based register 
machine architecture.  Although the instruction sets were limited at first, the 
languages allowed arbitrary computation per vertex and per fragment.  They are 
more efficient than the multi-pass approaches above, because they require 
much less memory bandwidth.  One disadvantage of assembly 
languages is that they are difficult for people to write and understand, as well as 
maintain, especially when programs get larger. One principal advantage of
assembly languages is that they are directly executed by the underlying
hardware. Due to the variability of graphics hardware, between and within
vendors, this is rarely the case for shader languages, making them less
attractive.

\subsection{Cg, HLSL}

Naturally, the next step beyond an assembly language is a high-level language 
that is compiled to it.  Cg \cite{mark03cg} and HLSL were created by NVIDIA and Microsoft, 
respectively, as C-like, high-level shading languages.  HLSL compiles to the 
Microsoft-defined vertex and pixel shader assembly architecture, which is loaded 
into the card at runtime.  Cg, on the other hand, compiles to a variety of back 
ends and is graphics API neutral.  The most recent NVIDIA cards have support 
for compiling Cg in the driver itself.

When referring to the language used by both Cg and HLSL, I will call it simply 
Cg.  For the sake of compatibility with other shading systems, and transparent 
access to the underlying hardware, Cg does very little work for the user. She is 
required to specify how data is transferred into the shaders and which attribute 
channels map to what. Cg also does not do any 
virtualization of resources, if a feature is not available.  This is not a criticism of 
Cg, just a description of the design decisions they made.

\subsection{GLSL}

While Cg and HLSL were being developed, 3DLabs and the OpenGL 
architecture review board were designing a shading language for the future of 
OpenGL.  The OpenGL shading language, or GL slang, or GLSL, had different 
goals than Cg and HLSL.  First, it is intended to become part of the OpenGL 
standard, replacing the assembly languages.  OpenGL implementers must have 
the shading language compiler in the driver itself, as opposed to an external 
process.  This means that applications that use the OpenGL shading language 
benefit from driver upgrades and compiler improvements for free.  It is also a 
forward thinking language design in that it requires all implementers to support 
things like conditionals and loops even if they can't do it in hardware.  The only 
thing that it does not require implementers to virtualize is things like using more 
texture units than are available, and accessing textures from the vertex shader.


\subsection{Sh}


Sh \cite{mccool02shader} isn't exactly a language, per se.  It is a metaprogramming system on top of 
C++ designed for building shaders.  Sh is implemented through a set of custom 
C++ objects that build an internal program representation when operations are 
applied to them.  This program is compiled to an underlying shader that is then 
run directly on the graphics card.  The advantage of a metaprogramming system 
such as this is that it has very tight integration with the host language. If the 
shader references a global variable, and assignments are made to that global variable outside 
the definition of the shader, it automatically becomes a uniform.  It also becomes 
natural to use the host languages features in order to specialize shaders.  For 
example, if when putting an if statement inside a shader, depending on the outcome of 
the condition, two different shaders are generated.  

The disadvantage of a 
metaprogramming system is that it requires a full C++ compiler to use a shader.  
Thus, shaders can't easily be passed along with 3-D models, 
limiting their usefulness to people who aren't programmers.  That said, there are 
some uses for shaders where a metaprogramming approach is ideal; such as 
implementation of custom graphics algorithms.


\subsection{Vertigo}


Vertigo \cite{elliott04vertigo} is a metaprogramming system like Sh, but built on top of Haskell instead 
of C++.  The interesting aspects of vertigo are that it is a functional language and 
eases expression rewriting for optimization.  Expression rewriting allows it to do 
an optimal search of expression space to reduce the amount of computation 
necessary to evaluate a particular expression.  A compelling example is that of 
vector normalization.  Vector normalization is a common requirements when 
writing graphics programs.  When writing a procedure, there is a choice 
between accepting a normalized vector, or any vector and then normalizing it 
explicitly.  Since normalization is expensive, normalizing a vector twice
should be avoided.  However, in a functional language it is possible to take advantage of 
referential transparency and expression rewriting to reduce the expression 
"normalize (normalize v) -> normalize v".  Once this optimization is available, there 
is no reason not to normalize a vector, if it needs to be normalized. Vertigo
shows how this is done in an elegant and automatic way.  


\section{Contributions}

Shading languages have traditionally followed the path of languages for general-
purpose processors, even when they aren't applicable.  Recent versions of Cg 
introduce a concept of interfaces, which have a syntax and description 
deceptively similar to interfaces in Java, even though the problem it tries to solve 
is better addressed by partial evaluation of functional programs.

In this paper we introduce a programming language for real-time graphics 
hardware that we believe addresses many of the problems in the existing 
languages, discussed above.  This language draws from existing research in 
modern pure functional languages, such as Haskell, Miranda, and Clean.  We 
based our design on functional languages for a variety of reasons.  First, 
functional languages have a very natural fit for the programming model exposed 
by graphics hardware.  Second, functional languages are traditionally easier to 
compile and perform static analysis on then imperative languages with side 
effects, such as C.  Third, our language is designed to have a minimum of 
extraneous syntax, making it much easier to learn and read.  We will now discuss 
these issues in detail.


This paper's primary contributions are the following:

- A pure functional programming language with a straightforward
  semantic model and syntax.

- Automatic computational frequency inference for optimal partitioning
  of program execution to four stages of the graphics pipeline.

- Natural shader composability that follows naturally from the simple
  execution model and frequency inference.

\section{Key Design Decisions (This title is copied straight from the Cg paper.  Is that bad?)}

\subsection{Functional Model}

--- DONE

An Introduction to Functional Programming (make this a subtitle?)

Renaissance is based on the syntax and semantics of modern, typed,
pure functional languages, specifically the family consisting of
Miranda, Clean, and Haskell.  Since we don't expect our audience to be
familiar with the syntax or semantics of these languages, let us introduce
the look and feel with an example.

\begin{verbatim}
pi = 3.1415927
square x = x * x
circumference r = pi * square r
\end{verbatim}

The first line defines a name "pi" to have the approximate value of pi.  The 
second line to find a function called "square" that takes one parameter and 
returns its square.  The third line defines the circumference, given a radius, to be 
pi times the square of the radius.  "square r" is the syntax for function application, 
and it means "apply the function square to the value r".  Notice that the example 
does not make any types explicit.  Types are inferred based on a definition's 
expression and any arguments.  So, above, "pi" has type 'float'.  square's type is 
't -> t', meaning "a function that takes type t and returns type t", where t is the 
type of the arguments.  So 'square 10' has type int and 'square 10.0' has type 
float.

There are no loops or variable assignments in this language.  Every
object, once created, cannot be changed.  This is called referential
transparency, which refers to the fact that if you call the same
function twice with the same arguments, you will always get the same
result back.

Modern GPUs have a stream programming model: there is 
a stream or array of data elements (vertices or fragments) and a function is 
applied across all of them.  This function, in stream programming terminology, is called a kernel.  Since all of the 
stream elements are independent, the function can be run in parallel without any 
sort of synchronization or data dependency analysis.  This is largely the reason 
why graphics processors these days are so efficient: performance increases linearly with the number of processors
available.  Previous shading languages 
have semantic models similar to C; that is, variables that 
can be modified and read from.  Further, the order statements are executed is critical.
Consider the following, C-like code:

\begin{verbatim}
int a = 1;

int foo() {
  a += 2;

  // Some code.
  return 10;
}

int bar() {
  a *= 3;

  // Other code.
  return 15;
}

void main() {
  int sum = foo() + bar();
  // do something with a
}
\end{verbatim}

The value of 'a' at the end of main() is either 9 or 5, depending on whether foo() or bar() is called first.
In general, this restriction complicates the compiler's task of optimization and static analysis.  A functional
language, on the other hand, is given a lot of freedom to reorder evaluation, because all dependencies
are explicit and no evaluation has side effects.  For specialized tasks, functional languages have been shown
to perform much more efficiently than equivalent C code.  [ref: ocaml, clean, sac]

As hardware programmability increases in capability and shaders get longer and larger, we believe a functional
language will scale in both performance and maintainability more than a language based on the imperative model of C.

Even ignoring the performance and ``compiler-friendly'' issues, functional languages are a better mental
model for the humans writing shaders as well.  It makes explicit that an operation on a stream element has no side
effects beyond the output value.  Other shading languages explicitly document that modifications to
global variables do not affect the program's operation on other stream elements.


\subsection{Frequency and Type Inference}

--- It ``smells'' to me like a lot of this should move into the language description.

Renaissance, as in most pure functional languages, C++, and other shading systems,
is a statically typed language.  That is, the type of an expression is associated with its name,
not its value.  However, Renaissance infers the type of an expression from context, so no types
need be specified explicitly.  Consider:

\begin{verbatim}
foo a b = a + bar b
bar b = b + 2
result = foo 10 4
\end{verbatim}

Notice that no types are explicitly specified.  However, when <var>result is evaluated, <var>foo 
is called with two integers and returns the sum of the first and <var>bar of the second.  
The result of this addition is an integer as well, so the value <var>result has type 
<type>int.  Consider the definition of a function that normalizes a vector:

\begin{verbatim}
normalize v = v / length v
\end{verbatim}

The operation of the function is clear even though its argument and return types are not 
specified.  This has a surprising side effect: the <def> normalize function actually 
represents several functions, each of different type.  Given that division by a 
scalar and the length function operate on multiple types of vectors, normalize itself 
will work with any vector.  This is similar to C++ template functions.


Cg, HLSL, and GLSL make explicit the difference between vertex and 
fragment programs, as well as the processing that must be done on the CPU before 
it is sent to the graphics card.  For early programmable hardware, this made sense, because vertex and 
fragment processors were sufficiently different.  Some operations were only 
possible on one or the other.  However, the trend right now used to provide a 
unified programmable interface to both stages of computation.  In fact, and 
DirectX 10 proposes a unified shader model.  Even on some of the later 
generation shading languages, the language itself is equivalent on both vertex 
and fragment engines.  The OpenGL shading language defines the same 
operations on both the fragment and vertex processors, but allows the 
implementation to restrict some operations.  For example, if the hardware does 
not support it, you are not allowed to read from textures in a vertex program.  For 
most operations however the limitation is forced to emulate the feature even if it 
is not supported in hardware.  In light of this trend, I language blurs the distinction 
between calculations that are specified on the processor, vertex processor, or 
fragment processor.  In most cases, the compiler can do just as good a job as a 
human at figuring out which operations need to be gone on which stage.  This 
simplifies the act of writing a shader.  You don't have to specifically worry about 
where computation is done.  You just write the shader in the most natural way 
possible and it gets compiled to the right code.

To implement this, we store a computational frequency (concept from RTS cell 
shading language) alongside the type of a computation.  Derived computations 
infer their frequency based on what they depend on.  We'll discuss this more fully 
in the description of the language.

Another advantage of combined shaders:  easy to share computation in both.


--- TODO:  this stuff below should go somewhere else
languages based on C's syntax are designed to be easy to parse by a computer, 
with human readability and writability as an afterthought.  They contain a lot of 
structural syntax, such as semicolons and braces, that can otherwise be implicit, 
as in the whitespace-sensitive languages Python and Haskell.  They also require 
tight specifications on variables, even when the expressions typed can be 
inferred.  Most modern functional languages are statically typed: that is, a name 
always refers to objects of the same type.  At the same time, automatic type 
inference allows the compiler to figure out the type of a name without being 
explicitly told what it is.  Consider the following psuedocode:




\subsection{Single Shader for Both Vertex and Pixel Pipelines}

---DONE

In contrast with the most popular real-time shading languages today, Cg, HLSL, 
and GLSL, we decided to blur the distinction between vertex 
shaders and fragment shaders.  One concern raised by NVIDIA in the design of Cg is that the different processors 
support different functionality, and by making the programs explicitly separate,
the differences are made clear.  [ref]  However, recent trends suggest that the vertex and fragment
processors will grow closer in functionality, rather than farther apart.  DirectX 10 is pushing for a unified 
processor architecture for both the vertex and fragment parts of the pipeline.  [ref]  ATI technology has 
also recently announced that they are unifying their two processors with a scheduling unit that manages the
load balancing between the two stages of the pipeline.  [ref]  With this in 
mind, we feel the potential confusion caused by executing "one" program on two 
potentially-different processors (in addition to the CPU) is worth the benefit in improved shader clarity,
maintainability, and optimization.

To mitigate the potential confusion brought about by this approach, we may allow specification of computational 
frequency explicitly, as RTSL does.  If a lower frequency is specified for a result than the values it depends on
(for example, if you claim that a result has a frequency of ``vertex'' but it depends on the fragment-frequency
gl\_FragCoord value), a compile-time error is raised.  Conversely, it might make sense to allow explicitly specifying
a higher frequency than would be inferred so as to force computation to occur later in the pipeline, which could
be a performance improvement in some cases.


\subsection{Shaders As Data Files}

---DONE

Following the example set by Cg and GLSL, it is critical that shaders can be treated 
as data files so that they can travel along with the models whose surfaces they 
describe.  Requiring a compilation step before being able to load or use a shader
greatly increases the amount of time it takes to iterate changes, especially for shader building tools and 
people who aren't programmers.  For this reason, the approach taken by
metaprogramming shading systems is infeasible for many uses of shaders, such as in games and
modeling software.  The 
convenience of being able to use a fully-featured general-purpose language for 
generation of your shaders is offset by the requirement of having a complete C++ 
or Haskell compiler in order to use your shaders at all.  Further, the basis of 
functional programming languages, the lambda calculus, provides
a very high degree of abstraction and notational convenience even with a 
naïve implementation.  Therefore, we can provide many of the important features of other high-level languages,
such as higher-order functions and specialization, with a minimum of effort.  Also, Vertigo shows that
an optimizing compiler from a functional language to GPU architectures is relatively straightforward,
especially compared to an optimizing C compiler.  In short, we believe a 'small' functional language
with a simple and powerful semantic model can satisfy the needs of shaders just as well as the
metaprogramming systems, without the requirement of a host environment.



\section{System Overview}

The Renaissance system is implemented in C++ and split into two pieces: the language, including its 
compiler, and the shader management API.

<insert diagram>

When the program loads a shader, it is parsed, and validated, and type checked
into an intermediate program structure.  The program can then set the value of
any constant inputs.  When the program is bound, the program is compiled into code that
can run on the GPU, optimized for the constant values that have been set.  The generated code is cached
with the constant values used to create it so recompilation is not necessary when
switching back and forth between shader states.

Setting uniforms and attributes does not invoke recompilation, since their values do not affect
the structure of the generated code.

One of the niceties of metaprogramming languages is that the interface between 
the host program and the shader is very convenient, since it can use native data types and structures.
Contrast this with the OpenGL shader APIs which require querying and managing uniform indices, and
use function names with 'warts' to distinguish between setting different uniform types:
glUniformfv and glUniformiv etc.  (TODO: what are the real names?)  We can get close to the convenience
of a metaprogramming language by providing custom C++ types that hide the internal data transfers.

\begin{verbatim}
ren::Bool enableBones(program, "enableBones");

enableBones = true;
program->bind();

enableBones = false;
program->bind();
\end{verbatim}

The next two sections define the language and the compiler in more detail.


\section{Language Description}

The syntax and semantics of Renaissance are very similar to the languages 
Miranda, Haskell, and Clean.

A program consists of two things:  inputs and definitions.  Each is separated by a 
newline.  (Renaissance is whitespace-sensitive.)

\subsection{Inputs}

There are three types of inputs, one for each of the first three computational 
frequencies: constants, uniforms, and vertex attributes.  Constant values are 
taken into account at compile time, uniforms at primitive group time, and 
attributes per vertex.  Since their type cannot be inferred, it must be made 
implicit:

\begin{verbatim}
constant bool enablePerPixelLighting
uniform mat3 colorMatrix
attribute float temperature
\end{verbatim}

\subsection{Definitions}

A definition either specifies a value or a function.

\begin{verbatim}
value = 2 + 2
function arg1 arg2 = arg1 / arg2
\end{verbatim}

'value' is a value of type int and function is a function of type 't * t -> t'.  
Technically, 'function's return type is not evaluated until it is called with 
arguments.  In this sense, 'function' actually refers to a template of possible 
functions which is instantiated at call time, similar to the operation of C++ 
templates.

Expressions consist of infix operators and function applications.  Precedence of 
operations is the same as in GLSL, function application having the highest 
priority.

Evaluation of functions is done lazily, as in Haskell, Miranda, and Clean.  This 
prevents redundant code generation:

\begin{verbatim}
constant bool doExpensive
choose expensive cheap = if doExpensive then expensive else 
cheap
gl_FragColor = choose ExpensiveCalculation CheapCalculation
\end{verbatim}

The arguments to <name>choose are only evaluated if necessary; that is, if doExpensive 
is true, then ExpensiveCalculation will be performed.  Otherwise, 
CheapCalculation will be performed.


\subsection{Types}

Following the conventions set by GLSL, we provide the following types:
bool, int, float, and vectors of 2 to 4 elements of each.  (vec2 is a
vector of two floats, vec3b is a vector of three bools, vec4i is a
vector of four integers, etc.)  There are also three square, float
matrix types: mat2, mat3, and mat4.  Texture samplers have type
``sampler1D'', ``sampler2D'', etc. just as in GLSL.

Arrays have type [t] where t is the type of its elements.  Since shading
hardware does not yet support variable-length arrays, the length of the array must be specified
at constant frequency.  In order to access the ith element of an array, treat it as a function,
calling it with parameter i.

In Renaissance, there are no implicit type conversions.  2 + 2.0 is a
type error, requiring a constructor conversion:  float 2 + 2.0


\subsection{Built-In Functions and Operators}

Once again, we provide access to all GLSL built-in functions, with the same names, types, overloads.

Texture access is done as in GLSL, with the exception that sampler
types may be called as functions with the lookup coordinates as the
parameter.

All of GLSL's built-in infix operators are available in Renaissance, with the same precedence.
Function calls have the highest precedence, but parentheses are available and operate as expected.
A new ++ operator is defined as vector concatenation, replacing GLSL's vector constructors.
Given two floats, concatening them with ++ returns a 2-element vector.  For example,
(vec3 1.2 3.4 5.6) ++ 7.8  ->  vec4 (1.2 3.4 5.6 7.8)


\subsection{Overloading and Swizzling}

Renaissance supports what is known as ad-hoc polymorphism, or overloading, 
based on the number and type of arguments.  For example, the expression "vec4 
1.0" and "vec4 1.0 1.0 1.0 1.0" are equally valid and have the same result.  There 
is a built-in "length" function which takes any vector of size 1 to 4 and returns its 
length.  Renaissance defines a special operator "." (from the language Nice) that 
calls the right hand side with the left hand side as its argument.  This means 
"length vec" and "vec.length" are equivalent.  This has nice property of allowing 
vector swizzling (vec.xyz) to be defined entirely within the standard library, 
although, for performance reasons, it will be special-cased.


\subsection{Composability}

As graphics teams begin to replace the entire fixed function pipeline with their 
own custom shading algorithms, the restriction that shaders must replace the 
entire pipeline becomes an increasing problem.  Moreover, it is nontrivial to write 
two independent pieces of the shading algorithms and combine them into one 
shader at runtime, even if they are independent in definition.  Some have solved 
this problem with elaborate preprocessors that combine the pieces into one 
shader that does not do any redundant computation.  Half-Life 2, for example, 
builds over 1500 shaders by combining pieces.

As a consequence of the functional programming model and frequency interface, 
Renaissance naturally supports composition.  Take a look at the following 
example code:

\begin{verbatim}
constant bool useLightingModel1
lightModel1 = ...  # calculations for light model 1
lightModel2 = ...  # calculations for light model 2
gl_FragColor = if useLightingModel1 then lightModel1 else 
lightModel2
\end{verbatim}

Since the variable useLightingModel1 has constant frequency, it is evaluated at 
shader compilation time.  Thus, the shader is specialized based on its value, with 
no extra computation per fragment.


\subsection{Abstraction Facilities}

Consider a vertex program that applies skeletal animation bone transformations 
to each vertex.  Traditionally, the program looks something like:

\begin{verbatim}
uniform [mat4] bones
attribute vec4 boneIndices
attribute vec4 weights

v0 = weights.x * ((bones boneIndices.x) * gl_Vertex)
v1 = weights.y * ((bones boneIndices.y) * gl_Vertex)
v2 = weights.z * ((bones boneIndices.z) * gl_Vertex)
v3 = weights.w * ((bones boneIndices.w) * gl_Vertex)
vertex = v0 + v1 + v2 + v3
gl_Position = gl_ModelViewProjectionMatrix * vertex
\end{verbatim}

Notice that this program has much duplicated logic and is hard-coded for the 
number of bones applied to each vertex.  One improvement would be to use a for 
loop or iteration construct to iterate over the bone references.  This would reduce 
the duplicated logic, but compilers for these languages do not claim to unroll 
loops and perform high-level optimizations like these.  Given frequency inference 
and higher-order-functions, however:

\begin{verbatim}
constant bool enableBones

uniform [mat4] bones
attribute vec4 boneIndices
attribute vec4 weights

skinnedVertex = sum [(weights i) * (bones (boneIndices i)) * gl_Vertex)
                     for i in (range 0 3)]
vertex = if enableBones then skinnedVertex else gl_Vertex
gl_Position = gl_ModelViewProjectionMatrix * vertex
\end{verbatim}

The syntax [expr for var in list] is called a list comprehension.  A new list is 
created by evaluating expr on every item in list.  In this case, the new list 
contains weighted vertices, which must be summed to get the result.  The sum 
function takes a list and returns the result of adding all its elements.

Using frequency inference and staged computation, this version of the shader 
provides a simple switch to enable and disable bone application.

\section{Runtime Description}

\subsection{Compiler Backend}

For simplicity of implementation and to leverage the extensive design work that 
went into the OpenGL Shading Language, we have chosen GLSL as the 
compiler target.  Also, several functional languages compile to C as it makes a 
very effective "portable assembly language".  <find a quote?>  Nothing in the 
language itself prevents other backends from being added in the future, however.

Shaders have special output definitions that are the ones actually responsible for 
generating code.  For example, if "gl\_Position" is defined, it must have type vec4 
and frequency of vertex or less.  Its evaluation becomes part of the vertex 
program.  If it and all other vertex-frequency outputs are not defined, a vertex 
program is not generated at all and the fixed function pipeline is used.  
gl\_Position is the only required vertex-frequency output.  gl\_FragColor is the only 
required fragment-frequency output.  These output variables can also be 
assigned the special value "undefined", which is equivalent to not giving a 
definition at all.  This is used in the following situation:

\begin{verbatim}
gl_FragColor = if enablePerPixelShading then getColor else undefined
\end{verbatim}

< factor these in if they haven't been already...
Design Decisions
?	Lazy evaluation.  This is a bit of a tricky issue.  You can think of the 
shader as being executed twice.  Once when the actual code to run on the 
hardware is generated.  And again when the generated code needs to be 
run, once per vertex or fragment.  The first "phase" is what enables 
efficient shader specialization and composition.  Since the graphics 
hardware itself does not support anything like general-purpose pointers it 
can't do lazy evaluation or any other modern programming language 
feature.  But the distinction between the first phase "the compilation 
phase" and execution phase is purposefully blurred so that the shader is 
more natural.
?	Performance and clear code.  As shaders grow, we contended that the C 
model of programming does not scale to efficient implementation, because 
of such things as side effects and aliasing (my bad, aliasing isn't actually a 
problem yet.  but it may be someday.).
>

Example Program

\begin{verbatim}
# Uniforms.

uniform vec3 LightPosition
uniform vec3 BrickColor
uniform vec3 MortarColor
uniform vec2 BrickSize
uniform vec2 BrickPct

# Constants.

SpecularContribution = 0.3
DiffuseContribution = 1.0 - SpecularContribution

# Transform.

gl_Position = ftransform
ecPosition = (gl_ModelViewMatrix * gl_Vertex).xyz
tnorm = normalize (gl_NormalMatrix * gl_Normal)

# Lighting.

lightVec   = normalize (LightPosition - ecPosition)
reflectVec = reflect (-lightVec) tnorm
viewVec    = normalize (-ecPosition)

diffuse = max (dot lightVec viewVec) 0.0
spec = if (diffuse > 0.0) then s else 0.0
    where s = pow (max (dot reflectVec viewVec) 0.0) 16.0
LightIntensity = DiffuseContribution * diffuse + 
                 SpecularContribution * specular

# Brick.

position = gl_Vertex.xy / BrickSize + (vec2 xoffset 0.0)
    where xoffset = if fract (position.y * 0.5) > 0.5 then 
0.5 else 0.0
useBrick = step (fract position) BrickPct

color = mix MortarColor BrickColor amount
    where amount = useBrick.x * useBrick.y * LightIntensity
gl_FragColor = color ++ 1.0  # gl_FragColor should have 
type vec4
\end{verbatim}

This is the standard OpenGL brick shader translated directly into Renaissance.

\section{Future Work}

expression rewriting

new backends

extension of pure functional language to effects framework, encompassing 
individual shading calculations, passes, and states

\section{Conclusion}

As programmable graphics hardware becomes more prevalent and
instruction and memory limitations are lifted and removed, a next
generation shading language will need to reduce the complexities
associated with transferring data and calculations from the host
application all the way down to the pixels on the screen.

This paper describes Renaissance, a shading language for modern
programmable GPUs that, through the benefits of functional
programming, enables efficient and clear algorithm specifications
across multiple stages of the graphics pipeline.  Through a simple
semantic model and frequency inference, natural composability of
shading ``concepts'' is possible, which existing languages make
difficult at best.  Extending this simple concept, we can imagine a
programmable shading system with configurable state that can be
flipped on and off, just like the interface to the fixed function
pipeline.

\section{Acknowledgements}

We would like to thank Conal Elliot for his work on Vertigo while at
Microsoft Research -- without it we would not have gotten far.  Thanks
also goes to Simon Peyton-Jones at Microsoft Research for his work on
the Haskell language and for releasing his out-of-print book The
Implementation of Functional Programming Languages.  Finally, Dusty
Leary and his infectious love of functional programming greatly influenced the
design of the language.



an example for a code insert:

%
\begin{figure}
\begin{verse}
\begin{verbatim}

for (int i = 0; i < 10; ++i)
cout << i;
cout << std::endl;

\end{verbatim}
\end{verse}

\caption{Code Example}
\end{figure}


But that won't let you freely format.

Alternatively you can just verbatimly include external files:

%
\begin{figure}
\verbatiminput{testcode.txt}


\caption{External Code Example}
\end{figure}


Note that using the browser will result in absolute filenames. Please
correct them to relative ones.

Including a picture (should be eps):

%
\begin{figure}
%\includegraphics{sampleFig.eps}


\caption{A Picture}
\end{figure}


References are handled using Bib\TeX{}. Take a look at the egbibsample.bib
file to see how to defines references. The URL-based stuff doesn't
work in \LyX{}, though, that we'll have to correct later. Usage is
very simple (Insert->Citation): \cite{Fellner-Helmberg93}

\bibliographystyle{eg-alpha}
\bibliography{cits}

\end{document}
